# AI本地知识库的构建

之前有分享过通过.NET Aspire在本地运行语言模型，有了这个能力后，我们就可以用它来做更多的事情，比如构建本地知识库。

## 基本知识

构建本地知识库的其中一种方式，是通过将我们的知识库数据进行向量化处理，然后存储到向量数据库中。在进行对话时，先查询我们的知识库内容，作为上下文，让语言模型获得相关知识，然后再返回给我们。

所以，我们将了解到以下内容：

- 向量化
- 向量化数据库
- 语言模型

## 模型选择

我们需要两个模型，一个是小语言模型，用来提供自然语言处理能力，另一个是嵌入模型，用来提供向量化能力。

### phi4-mini

选择phi4-mini，一个是性能不错，另一个是支持函数调用。

### nomic-embed-text

该嵌入模型提供768维度

## 使用.NET Aspire 部署ollama

我们将全部使用本地资源和实现我们的知识库，这就需要使用ollama来运行phi4-mini和nomic-embed-text模型。

.NET Aspire提供了非常简单的方式，我们只需要几行代码即可完成ollama的安装和模型的下载。

### 使用qdrant向量数据库

### 配置服务端口

使用固定的端口，以避免在每次运行时都需要重新配置端口。

## 预处理数据

要将数据存储到向量数据库中，我们需要将数据进行预处理，最终变化纯文本的数据。

这里我们以`markdown`文本为例，解释一下处理的过程。

### 文档拆分

将文本转换成向量然后进行存储，第一个问题就是，如何将文本进行拆分。

文本的拆分，可以以单词，句子，段落甚至整篇文章为单位进行向量化，其影响你搜索之后的结果。

在我们的场景中，建议使用段落或者文章为单位进行向量化。这样我们搜索的时候，能够获得更多的上下文内容，而不是单独的一个句子。

我们可以使用`markdig`类库直接将markdown文本转换成纯文本内容。

## 向量化存储

使用`nomic-embed-text`进行向量化处理，使用`qdrant`进行存储。

## 查询数据
